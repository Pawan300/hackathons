{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dancer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjhy63kQIRVn",
        "colab_type": "code",
        "outputId": "6c306d04-01bd-4192-eb78-57594a2740a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import PIL\n",
        "import cv2 ,pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb_BWgwDI9d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/test.csv\")\n",
        "train_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQQ42QZaJLDA",
        "colab_type": "code",
        "outputId": "56d8dbef-65d3-4c92-925c-a1cbbcb12070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>508.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>473.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>485.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image\n",
              "0  508.jpg\n",
              "1  246.jpg\n",
              "2  473.jpg\n",
              "3  485.jpg\n",
              "4  128.jpg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHqVpiYPJMiv",
        "colab_type": "code",
        "outputId": "7d739e64-ec9a-4d98-db9f-d4e9afd801f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.jpg</td>\n",
              "      <td>manipuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163.jpg</td>\n",
              "      <td>bharatanatyam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>450.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219.jpg</td>\n",
              "      <td>kathakali</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>455.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image         target\n",
              "0   96.jpg       manipuri\n",
              "1  163.jpg  bharatanatyam\n",
              "2  450.jpg         odissi\n",
              "3  219.jpg      kathakali\n",
              "4  455.jpg         odissi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYaOoIu5JOR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = []\n",
        "for i in train_data[\"Image\"]:\n",
        "    path = \"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/train/\"+i\n",
        "    img_data = cv2.imread(path)\n",
        "    img_data = cv2.resize(img_data, (224, 224), \n",
        "                           interpolation=cv2.INTER_NEAREST)\n",
        "    train.append(np.array(img_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVK2Pz02L685",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = []\n",
        "for i in test_data[\"Image\"]:\n",
        "  path = \"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/test/\"+i\n",
        "  img_data = cv2.imread(path)\n",
        "  img_data = cv2.resize(img_data, (224, 224), \n",
        "                           interpolation=cv2.INTER_NEAREST)\n",
        "  test.append(np.array(img_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQFoNf7GoE_b",
        "colab_type": "code",
        "outputId": "f8f8d277-ef51-4b68-e74b-02597b1ce208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKiEQJwcMWHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(train,open(\"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/train.npy\",\"wb\"))\n",
        "pickle.dump(test, open(\"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/test.npy\",\"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEBR0pgPM6js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img = pickle.load(open(\"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/test.npy\",\"rb\"))\n",
        "train_img = pickle.load(open(\"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/train.npy\",\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlLLJQWJM8je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img = np.array(train_img)\n",
        "test_img = np.array(test_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_USJJlkRcmG",
        "colab_type": "code",
        "outputId": "1a2f7eb0-9657-4e62-fe70-cd96370ddedc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.jpg</td>\n",
              "      <td>manipuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163.jpg</td>\n",
              "      <td>bharatanatyam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>450.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219.jpg</td>\n",
              "      <td>kathakali</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>455.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image         target\n",
              "0   96.jpg       manipuri\n",
              "1  163.jpg  bharatanatyam\n",
              "2  450.jpg         odissi\n",
              "3  219.jpg      kathakali\n",
              "4  455.jpg         odissi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gLICAtjRdRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_data[\"target\"])\n",
        "encoded_Y = encoder.transform(train_data[\"target\"])\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqqk7b6r5-x5",
        "colab_type": "code",
        "outputId": "72cfeb5e-2016-45f0-aff0-ab681f89ee9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dummy_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(364, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRwD_Se86LVU",
        "colab_type": "code",
        "outputId": "d419e046-911e-4568-a42a-6bf821b9e688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_img.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(364, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f1wNk4W6tbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cswm7Gr8JRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a Sequential model\n",
        "model= Sequential()\n",
        "model.add(Conv2D(kernel_size=(3,3), filters=3, activation='relu', input_shape=train_img[0].shape))\n",
        "model.add(Conv2D(filters=3,kernel_size = (3,3),activation='relu'))\n",
        "model.add(MaxPool2D(3,3))\n",
        "model.add(Conv2D(filters=3,kernel_size = (3,3),activation='relu'))\n",
        "model.add(MaxPool2D(3,3))\n",
        "model.add(Conv2D(filters=3,kernel_size = (3,3),activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(20,activation='relu'))\n",
        "model.add(Dense(15,activation='relu'))\n",
        "model.add(Dense(8,activation = 'softmax'))\n",
        "    \n",
        "model.compile(\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['acc'],\n",
        "              optimizer='adam'\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8oHwXbH_Cr1",
        "colab_type": "code",
        "outputId": "1b06eb09-8763-405b-c244-c694ca494d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_51 (Conv2D)           (None, 254, 254, 3)       84        \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 252, 252, 3)       84        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 84, 84, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 82, 82, 3)         84        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 27, 27, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 25, 25, 3)         84        \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 1875)              0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 20)                37520     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 15)                315       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 8)                 128       \n",
            "=================================================================\n",
            "Total params: 38,299\n",
            "Trainable params: 38,299\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z-dW7RfAwlO",
        "colab_type": "code",
        "outputId": "71cc8f64-de6c-4476-e3a0-67c9c8d34e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_img, dummy_y, epochs=50, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "364/364 [==============================] - 15s 40ms/step - loss: 5.2859 - acc: 0.1291\n",
            "Epoch 2/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 2.4833 - acc: 0.1511\n",
            "Epoch 3/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 2.1134 - acc: 0.1868\n",
            "Epoch 4/50\n",
            "364/364 [==============================] - 15s 40ms/step - loss: 1.9473 - acc: 0.2005\n",
            "Epoch 5/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 1.8400 - acc: 0.2610\n",
            "Epoch 6/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 1.7448 - acc: 0.3269\n",
            "Epoch 7/50\n",
            "364/364 [==============================] - 15s 41ms/step - loss: 1.6412 - acc: 0.3874\n",
            "Epoch 8/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 1.5429 - acc: 0.4341\n",
            "Epoch 9/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 1.4348 - acc: 0.4753\n",
            "Epoch 10/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 1.3246 - acc: 0.5275\n",
            "Epoch 11/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 1.2122 - acc: 0.5659\n",
            "Epoch 12/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 1.1064 - acc: 0.5907\n",
            "Epoch 13/50\n",
            "364/364 [==============================] - 15s 40ms/step - loss: 1.0015 - acc: 0.6538\n",
            "Epoch 14/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.8955 - acc: 0.6896\n",
            "Epoch 15/50\n",
            "364/364 [==============================] - 15s 41ms/step - loss: 0.7710 - acc: 0.7280\n",
            "Epoch 16/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.6642 - acc: 0.7747\n",
            "Epoch 17/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.5666 - acc: 0.8077\n",
            "Epoch 18/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.4786 - acc: 0.8489\n",
            "Epoch 19/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.4084 - acc: 0.8681\n",
            "Epoch 20/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.3397 - acc: 0.8956\n",
            "Epoch 21/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.2984 - acc: 0.9066\n",
            "Epoch 22/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.2543 - acc: 0.9341\n",
            "Epoch 23/50\n",
            "364/364 [==============================] - 15s 40ms/step - loss: 0.2176 - acc: 0.9423\n",
            "Epoch 24/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.1882 - acc: 0.9533\n",
            "Epoch 25/50\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.1609 - acc: 0.9560\n",
            "Epoch 26/50\n",
            "364/364 [==============================] - 15s 40ms/step - loss: 0.1356 - acc: 0.9643\n",
            "Epoch 27/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.1221 - acc: 0.9698\n",
            "Epoch 28/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.1088 - acc: 0.9670\n",
            "Epoch 29/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0976 - acc: 0.9725\n",
            "Epoch 30/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.0839 - acc: 0.9808\n",
            "Epoch 31/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0779 - acc: 0.9808\n",
            "Epoch 32/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0688 - acc: 0.9835\n",
            "Epoch 33/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0669 - acc: 0.9863\n",
            "Epoch 34/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.1040 - acc: 0.9753\n",
            "Epoch 35/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.1114 - acc: 0.9808\n",
            "Epoch 36/50\n",
            "364/364 [==============================] - 15s 40ms/step - loss: 0.0657 - acc: 0.9918\n",
            "Epoch 37/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0566 - acc: 0.9890\n",
            "Epoch 38/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0421 - acc: 0.9918\n",
            "Epoch 39/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0318 - acc: 0.9945\n",
            "Epoch 40/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0274 - acc: 0.9945\n",
            "Epoch 41/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0244 - acc: 0.9945\n",
            "Epoch 42/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0214 - acc: 0.9945\n",
            "Epoch 43/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0206 - acc: 0.9945\n",
            "Epoch 44/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0205 - acc: 0.9918\n",
            "Epoch 45/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0217 - acc: 0.9918\n",
            "Epoch 46/50\n",
            "364/364 [==============================] - 14s 40ms/step - loss: 0.0192 - acc: 0.9918\n",
            "Epoch 47/50\n",
            "364/364 [==============================] - 15s 40ms/step - loss: 0.0162 - acc: 0.9945\n",
            "Epoch 48/50\n",
            "364/364 [==============================] - 15s 41ms/step - loss: 0.0155 - acc: 0.9945\n",
            "Epoch 49/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0155 - acc: 0.9945\n",
            "Epoch 50/50\n",
            "364/364 [==============================] - 14s 39ms/step - loss: 0.0143 - acc: 0.9945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVvxDlISQqPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPQoCEAFBsGv",
        "colab_type": "code",
        "outputId": "b48bf641-f84d-447b-b7e6-d5ffb1c2ba52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsGK_nsoDB7b",
        "colab_type": "code",
        "outputId": "e5bebc99-6aae-4710-8f0c-24b36aa9d098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uydd-7ClDDpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict_classes(test_img)\n",
        "pred = encoder.inverse_transform(pred)\n",
        "result = pd.DataFrame(pred, test_data[\"Image\"], columns=[\"target\"])\n",
        "result.to_csv(\"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/sample.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljbS8rdGQoLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_5VJq31Dxrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zul1pH7LoWkW",
        "colab_type": "text"
      },
      "source": [
        "Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBgtWvVnoVt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsv7pUcxoVqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False, \n",
        "    input_shape=(224, 224, 3), \n",
        "    pooling='avg'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11xR-sCxoVof",
        "colab_type": "code",
        "outputId": "73bdf3b1-1b3c-4383-9897-a932935f861f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "  base_model,\n",
        "  Dropout(0.2),\n",
        "  Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 16392     \n",
            "=================================================================\n",
            "Total params: 23,604,104\n",
            "Trainable params: 16,392\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlwnFLYdoVlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/best_model.h5',\n",
        "                             monitor='val_loss', \n",
        "                             verbose=1, save_best_only= True, \n",
        "                             mode='auto')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPjPzs8aoViP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size =5\n",
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS9NWO4ioVeF",
        "colab_type": "code",
        "outputId": "39800cdd-3423-46b9-ba5d-5a4b5626dd02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "training_generator = datagen.flow(train_img, dummy_y,\n",
        "                                  batch_size=batch_size)\n",
        "\n",
        "history = model.fit_generator(\n",
        "         training_generator,\n",
        "         steps_per_epoch= training_generator.n//training_generator.batch_size,\n",
        "         callbacks=[checkpoint],\n",
        "         epochs= epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.1073 - accuracy: 0.9610\n",
            "Epoch 2/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0937 - accuracy: 0.9694\n",
            "Epoch 3/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0288 - accuracy: 0.9944\n",
            "Epoch 4/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0355 - accuracy: 0.9916\n",
            "Epoch 5/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0426 - accuracy: 0.9861\n",
            "Epoch 6/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0294 - accuracy: 0.9889\n",
            "Epoch 7/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0690 - accuracy: 0.9694\n",
            "Epoch 8/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0333 - accuracy: 0.9889\n",
            "Epoch 9/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0314 - accuracy: 0.9889\n",
            "Epoch 10/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0722 - accuracy: 0.9694\n",
            "Epoch 11/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9499WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.1172 - accuracy: 0.9499\n",
            "Epoch 12/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0972 - accuracy: 0.9749\n",
            "Epoch 13/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0347 - accuracy: 0.9889\n",
            "Epoch 14/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0328 - accuracy: 0.9916\n",
            "Epoch 15/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0392 - accuracy: 0.9889\n",
            "Epoch 16/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0358 - accuracy: 0.9916\n",
            "Epoch 17/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0244 - accuracy: 0.9916\n",
            "Epoch 18/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0254 - accuracy: 0.9889\n",
            "Epoch 19/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.1016 - accuracy: 0.9610\n",
            "Epoch 20/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0482 - accuracy: 0.9861\n",
            "Epoch 21/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0340 - accuracy: 0.9861\n",
            "Epoch 22/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0229 - accuracy: 0.9944\n",
            "Epoch 23/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0655 - accuracy: 0.9777\n",
            "Epoch 24/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0276 - accuracy: 0.9916\n",
            "Epoch 25/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0552 - accuracy: 0.9805\n",
            "Epoch 26/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9638WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0914 - accuracy: 0.9638\n",
            "Epoch 27/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0895 - accuracy: 0.9694\n",
            "Epoch 28/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0363 - accuracy: 0.9916\n",
            "Epoch 29/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0442 - accuracy: 0.9805\n",
            "Epoch 30/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0382 - accuracy: 0.9805\n",
            "Epoch 31/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0506 - accuracy: 0.9889\n",
            "Epoch 32/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0548 - accuracy: 0.9777\n",
            "Epoch 33/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0571 - accuracy: 0.9777\n",
            "Epoch 34/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9972WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0161 - accuracy: 0.9972\n",
            "Epoch 35/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0470 - accuracy: 0.9833\n",
            "Epoch 36/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 5s 63ms/step - loss: 0.0375 - accuracy: 0.9833\n",
            "Epoch 37/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 5s 63ms/step - loss: 0.0335 - accuracy: 0.9916\n",
            "Epoch 38/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0667 - accuracy: 0.9861\n",
            "Epoch 39/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0518 - accuracy: 0.9861\n",
            "Epoch 40/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9972WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0266 - accuracy: 0.9972\n",
            "Epoch 41/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0570 - accuracy: 0.9833\n",
            "Epoch 42/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0453 - accuracy: 0.9749\n",
            "Epoch 43/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0305 - accuracy: 0.9916\n",
            "Epoch 44/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0377 - accuracy: 0.9861\n",
            "Epoch 45/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9778WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0627 - accuracy: 0.9778\n",
            "Epoch 46/100\n",
            "71/72 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9859WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0315 - accuracy: 0.9861\n",
            "Epoch 47/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0166 - accuracy: 0.9944\n",
            "Epoch 48/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0709 - accuracy: 0.9805\n",
            "Epoch 49/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0647 - accuracy: 0.9861\n",
            "Epoch 50/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0592 - accuracy: 0.9777\n",
            "Epoch 51/100\n",
            "71/72 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9887WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0291 - accuracy: 0.9889\n",
            "Epoch 52/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0832 - accuracy: 0.9749\n",
            "Epoch 53/100\n",
            "71/72 [============================>.] - ETA: 0s - loss: 0.0516 - accuracy: 0.9803WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0510 - accuracy: 0.9805\n",
            "Epoch 54/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0526 - accuracy: 0.9721\n",
            "Epoch 55/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0471 - accuracy: 0.9916\n",
            "Epoch 56/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0413 - accuracy: 0.9889\n",
            "Epoch 57/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0364 - accuracy: 0.9889\n",
            "Epoch 58/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0434 - accuracy: 0.9833\n",
            "Epoch 59/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0216 - accuracy: 0.9916\n",
            "Epoch 60/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0648 - accuracy: 0.9721\n",
            "Epoch 61/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0794 - accuracy: 0.9777\n",
            "Epoch 62/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0477 - accuracy: 0.9833\n",
            "Epoch 63/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0366 - accuracy: 0.9916\n",
            "Epoch 64/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0323 - accuracy: 0.9916\n",
            "Epoch 65/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0172 - accuracy: 0.9944\n",
            "Epoch 66/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0572 - accuracy: 0.9833\n",
            "Epoch 67/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0197 - accuracy: 0.9889\n",
            "Epoch 68/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0309 - accuracy: 0.9889\n",
            "Epoch 69/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0632 - accuracy: 0.9805\n",
            "Epoch 70/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9554WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.1173 - accuracy: 0.9554\n",
            "Epoch 71/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0380 - accuracy: 0.9805\n",
            "Epoch 72/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0400 - accuracy: 0.9916\n",
            "Epoch 73/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0203 - accuracy: 0.9944\n",
            "Epoch 74/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0301 - accuracy: 0.9889\n",
            "Epoch 75/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0135 - accuracy: 0.9944\n",
            "Epoch 76/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9917WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0327 - accuracy: 0.9917\n",
            "Epoch 77/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0172 - accuracy: 0.9944\n",
            "Epoch 78/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0532 - accuracy: 0.9833\n",
            "Epoch 79/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0765 - accuracy: 0.9805\n",
            "Epoch 80/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0230 - accuracy: 0.9916\n",
            "Epoch 81/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 82/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 62ms/step - loss: 0.0416 - accuracy: 0.9889\n",
            "Epoch 83/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0140 - accuracy: 0.9944\n",
            "Epoch 84/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0387 - accuracy: 0.9916\n",
            "Epoch 85/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0262 - accuracy: 0.9889\n",
            "Epoch 86/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0618 - accuracy: 0.9833\n",
            "Epoch 87/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0579 - accuracy: 0.9861\n",
            "Epoch 88/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 59ms/step - loss: 0.0271 - accuracy: 0.9944\n",
            "Epoch 89/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0479 - accuracy: 0.9805\n",
            "Epoch 90/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0661 - accuracy: 0.9749\n",
            "Epoch 91/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0394 - accuracy: 0.9889\n",
            "Epoch 92/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0437 - accuracy: 0.9805\n",
            "Epoch 93/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0887 - accuracy: 0.9749\n",
            "Epoch 94/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0523 - accuracy: 0.9833\n",
            "Epoch 95/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0708 - accuracy: 0.9777\n",
            "Epoch 96/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0301 - accuracy: 0.9916\n",
            "Epoch 97/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0186 - accuracy: 0.9916\n",
            "Epoch 98/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0254 - accuracy: 0.9916\n",
            "Epoch 99/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 60ms/step - loss: 0.0270 - accuracy: 0.9916\n",
            "Epoch 100/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 61ms/step - loss: 0.0335 - accuracy: 0.9861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6O82lZQoVYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(test_img)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "test_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/test.csv\")\n",
        "\n",
        "pred = encoder.inverse_transform(pred)\n",
        "result = pd.DataFrame(pred, test_data[\"Image\"], columns=[\"target\"])\n",
        "result.to_csv(\"/content/drive/My Drive/Colab Notebooks/dl_comptetion/dataset/sample.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTPjtUpToVVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqsXfzSkoVR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}