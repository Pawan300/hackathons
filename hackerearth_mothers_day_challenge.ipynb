{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques I tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "  \n",
    "import gensim \n",
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, json, re\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/train.csv\")\n",
    "test_data = pd.read_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/test.csv\")\n",
    "with open(\"/home/hackerearth/Downloads/contractions.json\", \"r\") as file:\n",
    "    contractions = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding using BERT  as a service : (This code is not including in the file because it is running in the local server of bert in cmd)\n",
    "steps :-\n",
    "a: pip install tensorflow==1.15.0\n",
    "b: pip install -U bert-serving\n",
    "c: bert-serving-start - model_dir -num_workers\n",
    "Meanwhile in python:\n",
    "from bert_serving.client import BertClient\n",
    "b = BertClient()\n",
    "b.encode([\"string\"])\n",
    "\n",
    "After getting embedding from here I tried many classifiers like Logistic regresssion, Random Forest, XGBoost, Decision tree with their respective grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3235, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.245025e+18</td>\n",
       "      <td>Happy #MothersDay to all you amazing mothers o...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>BeenXXPired</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.245759e+18</td>\n",
       "      <td>Happy Mothers Day Mum - I'm sorry I can't be t...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>FestiveFeeling</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.246087e+18</td>\n",
       "      <td>Happy mothers day To all This doing a mothers ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>KrisAllenSak</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.244803e+18</td>\n",
       "      <td>Happy mothers day to this beautiful woman...ro...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Queenuchee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.244876e+18</td>\n",
       "      <td>Remembering the 3 most amazing ladies who made...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>brittan17446794</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                      original_text lang  \\\n",
       "0  1.245025e+18  Happy #MothersDay to all you amazing mothers o...   en   \n",
       "1  1.245759e+18  Happy Mothers Day Mum - I'm sorry I can't be t...   en   \n",
       "2  1.246087e+18  Happy mothers day To all This doing a mothers ...   en   \n",
       "3  1.244803e+18  Happy mothers day to this beautiful woman...ro...   en   \n",
       "4  1.244876e+18  Remembering the 3 most amazing ladies who made...   en   \n",
       "\n",
       "  retweet_count  original_author  sentiment_class  \n",
       "0             0      BeenXXPired                0  \n",
       "1             1   FestiveFeeling                0  \n",
       "2             0     KrisAllenSak               -1  \n",
       "3             0       Queenuchee                0  \n",
       "4             0  brittan17446794               -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1387, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.246628e+18</td>\n",
       "      <td>3. Yeah, I once cooked potatoes when I was 3 y...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>LToddWood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.245898e+18</td>\n",
       "      <td>Happy Mother's Day to all the mums, step-mums,...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>iiarushii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.244717e+18</td>\n",
       "      <td>I love the people from the UK, however, when I...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>andreaanderegg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.245730e+18</td>\n",
       "      <td>Happy 81st Birthday Happy Mother’s Day to my m...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>TheBookTweeters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.244636e+18</td>\n",
       "      <td>Happy Mothers day to all those wonderful mothe...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>andreaanderegg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                      original_text lang  \\\n",
       "0  1.246628e+18  3. Yeah, I once cooked potatoes when I was 3 y...   en   \n",
       "1  1.245898e+18  Happy Mother's Day to all the mums, step-mums,...   en   \n",
       "2  1.244717e+18  I love the people from the UK, however, when I...   en   \n",
       "3  1.245730e+18  Happy 81st Birthday Happy Mother’s Day to my m...   en   \n",
       "4  1.244636e+18  Happy Mothers day to all those wonderful mothe...   en   \n",
       "\n",
       "  retweet_count  original_author  \n",
       "0             0        LToddWood  \n",
       "1             0        iiarushii  \n",
       "2             0   andreaanderegg  \n",
       "3             1  TheBookTweeters  \n",
       "4             0   andreaanderegg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    1701\n",
       "-1     769\n",
       " 1     765\n",
       "Name: sentiment_class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"sentiment_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "a: remove urls\n",
    "b: punctuations\n",
    "c: stopwords \n",
    "d: lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(data):\n",
    "    temp = []\n",
    "    for i in data:\n",
    "        i = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))|https''', '', i, flags=re.MULTILINE)\n",
    "        #i = re.sub(r'^https?|:\\/\\/.*[\\r\\n]*|https', '', i, flags=re.MULTILINE)\n",
    "        temp.append(i)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = remove_url(train_data[\"original_text\"])\n",
    "test = remove_url(test_data[\"original_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean punctuation\n",
    "def clean_punctuation(data):\n",
    "    punctuation = re.compile(r'[-.?!,#@=$%^&*_\\><\":;()|0-9]')\n",
    "    temp =[]\n",
    "    for i in data:\n",
    "        temp.append([punctuation.sub(\"\",j) for j in i.split(\" \") \n",
    "                     if j not in contractions.keys() and\n",
    "                     punctuation.sub(\"\",j) not in stop_words and \n",
    "                    len(punctuation.sub(\"\",j))>1])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clean_punctuation(train)\n",
    "test = clean_punctuation(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/hackerearth/Desktop/ml_comptetion/dataset/train.txt\",'w') as file:\n",
    "    for listitem in train:\n",
    "        file.write('%s\\n' % listitem)\n",
    "with open(\"/home/hackerearth/Desktop/ml_comptetion/dataset/test.txt\",'w') as file:\n",
    "    for listitem in train:\n",
    "        file.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[:]\n",
    "data.extend(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec inclusing many classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(data, min_count = 1,  \n",
    "                              size = 1024, window = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(data):\n",
    "    temp =[]\n",
    "    for i in data:\n",
    "        l = []\n",
    "        for j in i:\n",
    "            l.append(np.reshape(model[j],(1,1024)))\n",
    "        l=np.average(np.array(l),axis=0)\n",
    "        temp.append(l)\n",
    "    return temp\n",
    "train_emb = embedding(train)\n",
    "test_emb = np.array(embedding(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_emb = np.concatenate(train_emb, axis=0)\n",
    "#test_emb = np.concatenate(test_emb, axis=0)\n",
    "\n",
    "#............. Bert embeddings ..............#\n",
    "\n",
    "import pickle\n",
    "train_emb = pickle.load(open(\"/home/hackerearth/Desktop/ml_comptetion/dataset/train2.npy\",'rb'))\n",
    "test_emb = pickle.load(open(\"/home/hackerearth/Desktop/ml_comptetion/dataset/test2.npy\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = np.reshape(train_emb,(3235,1024))\n",
    "test_emb = np.reshape(test_emb,(1387,1024))\n",
    "y_labels = train_data[\"sentiment_class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_model(train_emb, y_labels):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    a =[]\n",
    "    for i in range(10):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(train_emb, y_labels, train_size=0.8)\n",
    "        model = LogisticRegression(solver = 'lbfgs')\n",
    "        model.fit(x_train,y_train)\n",
    "        predict_label = model.predict(x_test)\n",
    "        a.append(accuracy_score(predict_label, y_test))\n",
    "    print(np.array(a).mean())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43168469860896447\n"
     ]
    }
   ],
   "source": [
    "model = LR_model(train_emb, y_labels)\n",
    "prediction = model.predict(test_emb)\n",
    "\n",
    "result = pd.DataFrame(prediction, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.001, 'penalty': 'l2'}\n",
      "accuracy : 0.531298075484122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_emb, y_labels, train_size=0.8)\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(x_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2=LogisticRegression(C=0.001,penalty=\"l2\")\n",
    "logreg2.fit(train_emb,y_labels)\n",
    "prediction = logreg2.predict(test_emb)\n",
    "\n",
    "result = pd.DataFrame(prediction, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR + somte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_model_smote(train_emb, y_labels):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    a =[]\n",
    "    smote = SMOTE('minority')\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_emb, y_labels, train_size=0.8)\n",
    "    x_train, y_train = smote.fit_sample(x_train, y_train)\n",
    "    model = LogisticRegression(solver = 'lbfgs')\n",
    "    model.fit(x_train,y_train)\n",
    "    predict_label = model.predict(x_test)\n",
    "    a.append(accuracy_score(predict_label, y_test))\n",
    "    print(np.array(a).mean())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39258114374034003\n"
     ]
    }
   ],
   "source": [
    "model = LR_model_smote(train_emb, y_labels)\n",
    "prediction = model.predict(test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(prediction, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_labels)\n",
    "encoded_Y = encoder.transform(y_labels)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hackerearth/anaconda3/envs/company/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/hackerearth/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 1.0552 - accuracy: 0.5202\n",
      "Epoch 2/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 1.0246 - accuracy: 0.5243\n",
      "Epoch 3/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 1.0232 - accuracy: 0.5258\n",
      "Epoch 4/50\n",
      "3235/3235 [==============================] - 8s 3ms/step - loss: 1.0243 - accuracy: 0.5255\n",
      "Epoch 5/50\n",
      "3235/3235 [==============================] - 8s 2ms/step - loss: 1.0258 - accuracy: 0.5215\n",
      "Epoch 6/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 1.0215 - accuracy: 0.5270\n",
      "Epoch 7/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 1.0220 - accuracy: 0.5243\n",
      "Epoch 8/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 1.0163 - accuracy: 0.5277\n",
      "Epoch 9/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 1.0126 - accuracy: 0.5274\n",
      "Epoch 10/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 1.0003 - accuracy: 0.5342\n",
      "Epoch 11/50\n",
      "3235/3235 [==============================] - 8s 2ms/step - loss: 0.9854 - accuracy: 0.5397\n",
      "Epoch 12/50\n",
      "3235/3235 [==============================] - 8s 2ms/step - loss: 0.9704 - accuracy: 0.5440\n",
      "Epoch 13/50\n",
      "3235/3235 [==============================] - 8s 3ms/step - loss: 0.9526 - accuracy: 0.5539\n",
      "Epoch 14/50\n",
      "3235/3235 [==============================] - 8s 2ms/step - loss: 0.9343 - accuracy: 0.5641\n",
      "Epoch 15/50\n",
      "3235/3235 [==============================] - 8s 3ms/step - loss: 0.9040 - accuracy: 0.5716\n",
      "Epoch 16/50\n",
      "3235/3235 [==============================] - 8s 2ms/step - loss: 0.8988 - accuracy: 0.5774\n",
      "Epoch 17/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.8721 - accuracy: 0.5855\n",
      "Epoch 18/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 0.8612 - accuracy: 0.5932\n",
      "Epoch 19/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.8379 - accuracy: 0.5966\n",
      "Epoch 20/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.8153 - accuracy: 0.6164\n",
      "Epoch 21/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 0.7944 - accuracy: 0.6207\n",
      "Epoch 22/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 0.7837 - accuracy: 0.6204\n",
      "Epoch 23/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 0.7764 - accuracy: 0.6219\n",
      "Epoch 24/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 0.7735 - accuracy: 0.6253\n",
      "Epoch 25/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.7569 - accuracy: 0.6340\n",
      "Epoch 26/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.7274 - accuracy: 0.6371\n",
      "Epoch 27/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.7187 - accuracy: 0.6467\n",
      "Epoch 28/50\n",
      "3235/3235 [==============================] - 8s 3ms/step - loss: 0.7206 - accuracy: 0.6445\n",
      "Epoch 29/50\n",
      "3235/3235 [==============================] - 8s 3ms/step - loss: 0.7150 - accuracy: 0.6495\n",
      "Epoch 30/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.6839 - accuracy: 0.6516\n",
      "Epoch 31/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 0.6862 - accuracy: 0.6572\n",
      "Epoch 32/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.6761 - accuracy: 0.6615\n",
      "Epoch 33/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 0.6720 - accuracy: 0.6680\n",
      "Epoch 34/50\n",
      "3235/3235 [==============================] - 12s 4ms/step - loss: 0.6570 - accuracy: 0.6696\n",
      "Epoch 35/50\n",
      "3235/3235 [==============================] - 11s 4ms/step - loss: 0.6373 - accuracy: 0.6785\n",
      "Epoch 36/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 0.6285 - accuracy: 0.6804\n",
      "Epoch 37/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.6471 - accuracy: 0.6832\n",
      "Epoch 38/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 0.6345 - accuracy: 0.6835\n",
      "Epoch 39/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 0.6450 - accuracy: 0.6841\n",
      "Epoch 40/50\n",
      "3235/3235 [==============================] - 10s 3ms/step - loss: 0.6082 - accuracy: 0.6918\n",
      "Epoch 41/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 0.5856 - accuracy: 0.6943\n",
      "Epoch 42/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 0.6070 - accuracy: 0.6862\n",
      "Epoch 43/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.5798 - accuracy: 0.7026\n",
      "Epoch 44/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 0.6395 - accuracy: 0.6816\n",
      "Epoch 45/50\n",
      "3235/3235 [==============================] - 11s 3ms/step - loss: 0.6070 - accuracy: 0.6921\n",
      "Epoch 46/50\n",
      "3235/3235 [==============================] - 8s 3ms/step - loss: 0.6021 - accuracy: 0.7054\n",
      "Epoch 47/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.5656 - accuracy: 0.7039\n",
      "Epoch 48/50\n",
      "3235/3235 [==============================] - 8s 2ms/step - loss: 0.5877 - accuracy: 0.6995\n",
      "Epoch 49/50\n",
      "3235/3235 [==============================] - 8s 2ms/step - loss: 0.5657 - accuracy: 0.7113\n",
      "Epoch 50/50\n",
      "3235/3235 [==============================] - 9s 3ms/step - loss: 0.5646 - accuracy: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f17e97f5710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = train_emb.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim = input_dim , activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "\n",
    "model.fit(train_emb, dummy_y, epochs = 50, batch_size = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(test_emb)\n",
    "result = pd.DataFrame(prediction, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree():\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_emb, y_labels, train_size=0.8)\n",
    "    parameters = {'min_samples_split' : range(10,500,20),'max_depth': range(1,20,2)}\n",
    "    clf_tree = DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(clf_tree ,parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(test_emb)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = decision_tree()\n",
    "result = pd.DataFrame(pred, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scs():\n",
    "    from sklearn.svm import SVC \n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_emb, y_labels, train_size=0.8)\n",
    "    param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}  \n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "    grid.fit(x_train, y_train) \n",
    "    prediction = grid.predict(test_emb)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.525, total=  16.2s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.525, total=  16.1s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   32.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.525, total=  16.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.526, total=  16.2s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.526, total=  16.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.525, total=  16.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.525, total=  16.4s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.525, total=  16.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.526, total=  16.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.526, total=  15.9s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.525, total=  14.6s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.525, total=  14.9s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.525, total=  14.6s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.526, total=  14.6s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.526, total=  15.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.525, total=  13.9s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.525, total=  13.6s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.525, total=  13.7s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.526, total=  14.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.526, total=  14.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.525, total=  12.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.525, total=  12.2s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.525, total=  11.7s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.526, total=  11.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.526, total=  11.7s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.527, total=  16.4s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.529, total=  16.3s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.521, total=  15.6s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.530, total=  16.1s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.522, total=  16.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.527, total=  16.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.531, total=  16.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.527, total=  15.7s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.528, total=  15.6s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.522, total=  16.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.527, total=  15.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.525, total=  15.2s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.525, total=  15.5s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.528, total=  15.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.528, total=  14.8s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.525, total=  13.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.525, total=  13.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.525, total=  13.8s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.526, total=  13.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.526, total=  14.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.525, total=  13.7s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.525, total=  14.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.525, total=  14.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.526, total=  14.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.526, total=  15.2s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.527, total=  17.8s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.529, total=  16.6s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.521, total=  16.8s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.528, total=  16.4s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.522, total=  16.5s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.521, total=  16.6s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.529, total=  16.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.521, total=  16.5s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.524, total=  16.5s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.522, total=  16.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.463, total=  16.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.454, total=  16.1s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.442, total=  16.6s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.445, total=  16.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.439, total=  17.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.527, total=  13.5s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.525, total=  13.7s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.525, total=  13.7s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.528, total=  13.6s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.528, total=  13.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.525, total=  14.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.525, total=  13.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.525, total=  13.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.526, total=  13.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.526, total=  13.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.527, total=  16.2s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.529, total=  16.2s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.521, total=  16.2s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.528, total=  16.3s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.522, total=  16.2s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.521, total=  16.1s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.529, total=  16.1s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.521, total=  16.1s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.524, total=  16.1s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.522, total=  16.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.461, total=  16.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.434, total=  16.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.434, total=  16.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.424, total=  16.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.441, total=  16.1s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.440, total=  13.6s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.461, total=  13.7s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.419, total=  13.7s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.431, total=  13.8s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.445, total=  13.7s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.527, total=  13.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.525, total=  13.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.525, total=  13.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.528, total=  13.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.528, total=  13.4s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.527, total=  16.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.529, total=  16.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.521, total=  16.1s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.528, total=  16.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.522, total=  16.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.521, total=  16.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.529, total=  16.2s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.521, total=  16.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.524, total=  16.2s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.522, total=  16.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.459, total=  16.3s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.440, total=  16.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.434, total=  16.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.424, total=  16.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.439, total=  16.1s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.419, total=  18.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.413, total=  17.8s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.369, total=  17.7s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.412, total=  17.8s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.395, total=  17.5s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.446, total=  13.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.454, total=  13.6s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.415, total=  13.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.447, total=  13.6s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.441, total=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed: 31.7min finished\n"
     ]
    }
   ],
   "source": [
    "pred = scs()\n",
    "result = pd.DataFrame(pred, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier    \n",
    "x_train, x_test, y_train, y_test = train_test_split(train_emb, y_labels, train_size=0.8)\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 5, 8, 15, 20],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "classifier = RandomForestClassifier(random_state = 42)\n",
    "CV_rfc = GridSearchCV(estimator=classifier, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(x_train, y_train)\n",
    "CV_rfc.best_params_    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc1=RandomForestClassifier(max_features='log2', n_estimators= 10, \n",
    "                            max_depth=4, criterion='entropy')\n",
    "rfc1.fit(x_train, y_train)\n",
    "pred = rfc1.predict(test_emb)\n",
    "result = pd.DataFrame(pred, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:53:51] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { num_classes } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB classifier\n",
    "import xgboost as xgb\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_emb, y_labels, train_size=0.8)\n",
    "clf = xgb.XGBClassifier(max_depth=5, objective='multi:softmax', n_estimators=1000, \n",
    "                        num_classes=9)\n",
    "clf.fit(x_train, y_train)  \n",
    "pred = clf.predict(test_emb)\n",
    "result = pd.DataFrame(pred, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_emb, y_labels, train_size=0.8)\n",
    "clf = GradientBoostingClassifier(n_estimators=20, learning_rate=0.8\n",
    "                                 , max_features=2, max_depth=2, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(test_emb)\n",
    "result = pd.DataFrame(pred, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {'n_estimators':range(20,81,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                                               min_samples_split=500,\n",
    "                                                               min_samples_leaf=50,\n",
    "                                                               max_depth=8,max_features='sqrt',\n",
    "                                                               subsample=0.8,random_state=10),param_grid = param_test1, \n",
    "                                                               scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_emb, y_labels, train_size=0.8)\n",
    "gsearch1.fit(x_train, y_train)\n",
    "pred = gsearch1.predict(test_emb)\n",
    "result = pd.DataFrame(pred, test_data[\"id\"], columns=[\"sentiment_class\"])\n",
    "result.to_csv(\"/home/hackerearth/Desktop/ml_comptetion/dataset/sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
